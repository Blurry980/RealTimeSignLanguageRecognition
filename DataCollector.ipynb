{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4110b72",
   "metadata": {},
   "source": [
    "### Installed opencv, labelImg, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5d7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install labelImg\n",
    "#!pip install --upgrade pyqt5 lxml\n",
    "#!pip list\n",
    "#!qmake --version\n",
    "#!pip install pyqt5\n",
    "#!pip uninstall pyqt5\n",
    "#!pip install pyqt5\n",
    "# import PyQt5.QtCore\n",
    "# import sip\n",
    "# from PyQt5.QTGui import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ba143",
   "metadata": {},
   "source": [
    "### Imported Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0907bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #opencv\n",
    "import time #gives us time so we can move hands while collecting images\n",
    "import uuid #used to name image files\n",
    "import os #helps work with file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a30d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'Tensorflow/workspace/images/collectedimages'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa94b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# subprocess.run(['labelImg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4444a184",
   "metadata": {},
   "source": [
    "### Cloned labeImg package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23184fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')\n",
    "\n",
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/heartexlabs/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73a350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pyrcc5' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !cd {LABELIMG_PATH} && make qt5py3\n",
    "if os.name == 'nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc\n",
    "\n",
    "#!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cc381",
   "metadata": {},
   "source": [
    "### With the help of ChatGBT, I was able to come up with code that allowed me to have more control over when images are captured and when to move to the next letter by keyboard presses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce24bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/images/collectedimages\\a\\a.2697bb8a-de1d-11ed-90bf-9cfce869da1a.jpg written!\n",
      "Quitting...\n"
     ]
    }
   ],
   "source": [
    "# Set up the directory structure\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
    "# if not os.path.exists('dataset'):\n",
    "#     os.makedirs('dataset')\n",
    "for label in labels:\n",
    "    !mkdir {'Tensorflow\\workspace\\images\\collectedimages\\\\'+label}\n",
    "#     if not os.path.exists('dataset/'+label):\n",
    "#         os.makedirs('dataset/'+label)\n",
    "\n",
    "# Set up the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the current letter and image count\n",
    "current_letter = 0\n",
    "image_count = 0\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Check for user input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Take an image if the user presses the spacebar\n",
    "    if key == ord(' '):\n",
    "        # Save the image to the appropriate directory\n",
    "        label = labels[current_letter]\n",
    "        #filename = 'dataset/'+label+'/'+str(image_count)+'.jpg'\n",
    "        filename = os.path.join(IMAGES_PATH, label, label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print('{} written!'.format(filename))\n",
    "        image_count += 1\n",
    "\n",
    "    # Move to the next letter if the user presses a key\n",
    "    if key == ord('n'):\n",
    "        current_letter += 1\n",
    "        print(f\"Going to next letter: {labels[current_letter]}\")\n",
    "        image_count = 0\n",
    "        if current_letter >= len(labels):\n",
    "            break\n",
    "            \n",
    "    if key == ord('q'):\n",
    "        print(\"Quitting...\")\n",
    "        break\n",
    "\n",
    "# Release the capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b668f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9481ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57097c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
